#!/usr/bin/env python
#
from __future__ import with_statement
from __future__ import print_function

import tempfile
import hashlib
import os
import pwd
import re
import sys
import csv
import eups

sep = "\a"                              # field separator (as values can contain whitespace)
ignoredProducts = ["implicitProducts"]


def quote_path(path):
    """Quote a file path suitable for Doxygen config files.
       Doxygen requires double quotes rather than single quotes
       so pipes.quote() can not be used. Only quotes a path
       if there are spaces in it."""
    if " " in path:
        return '"{}"'.format(path)
    return path

class Doxyfile(object):
    """Represent a doxygen configuration file"""

    def __init__(self, productName, versionName=None,
                 docDir="doc", configFile="doxygen.conf"):
        """Read and parse productName's config file.

        We'll look for it in eups"""

        self.productName = productName
        self.entries = {}
        self.mainpage = None
        #
        pdir = eups.productDir(productName, versionName)  # Look in the eups productDir
        if pdir and os.path.exists(os.path.join(pdir, docDir, configFile)):
            self.baseDir = pdir
        else:
            if productName == "lsstDoxygen":
                raise RuntimeError("Please run scons on lsstDoxygen and try again")

            if configFile is None:
                return

            if productName in ignoredProducts:
                return

            raise RuntimeError("Unable to find %s's %s file" % (productName, configFile))

        self.docDir = os.path.join(self.baseDir, docDir)

        try:
            body = [l for l in open(os.path.join(self.docDir, configFile)).readlines()
                    if not re.search(r"^\s*#", l)]
        except IOError as e:
            print(e, file=sys.stderr)
            return

        body = re.sub(r"\n+", "\n", "".join(body))
        body = re.sub(r"\s*\\\n+\s*", sep, body)

        # List of path-like doxygen configuration options
        PATH_LIKE = ("EXAMPLE_PATH", "EXCLUDE", "INCLUDE_PATH", "@INCLUDE_PATH", "INPUT", "IMAGE_PATH",
                     "GENERATE_TAGFILE")

        for entry in body.split("\n"):
            entry0 = entry              # for debugging
            if re.search(r"^\s*$", entry):
                continue

            mat = re.search(r"^\s*(\S+)\s*\+?=\s*(.*)", entry)
            assert mat

            values = []
            name = mat.group(1)
            is_path_name = name in PATH_LIKE

            entries = mat.group(2)

            # Path entries can be double-quoted if they are paths that might contain spaces
            # An entry could look like: a "b c" "d" or "a b" c d
            # Use the csv package to handle this.
            # We have to be careful to only do this processing on PATH-like doxygen components
            if is_path_name:
                csv_reader = csv.reader([entries], delimiter=' ', quotechar='"')
                outstr = sep.join(next(csv_reader))

                # it is possible that we have multiple spaces delimiting items so we
                # need to compress the separators
                entries = re.sub(sep + "+", sep, outstr)
            else:
                # Replace spaces with separators unless the string contains a double quote
                if not re.search(r'"', entries):
                    entries = re.sub(r"\s+", sep, entries)

            # Remove all single and double quotes
            entries = re.sub("[\"']", "", entries)

            for entry in [e.strip() for e in entries.split(sep)]:
                if not entry:
                    continue

                if is_path_name:
                    entry = os.path.normpath(os.path.join(self.docDir, entry))
                    #
                    # At least early in the Winter2012 refactoring, the doxygen.conf files refer to
                    # the build directories, not the as-installed locations, of the doxygenated files
                    #
                    entry0 = entry
                    mat = re.search(r"\"?(.*)/(doc|include|examples|python|src|tests)/?([^\s\"]*)\"?$", entry)
                    if mat:
                        pre, d, post = mat.groups()
                        entry = os.path.join(pdir, d, post)

                    if not os.path.exists(entry):
                        if os.path.exists(entry0):
                            entry = entry0
                        else:
                            continue

                if name == "INPUT":
                    # Look for \mainpage tags
                    for path, dirs, files in os.walk(entry):
                        for f in files:
                            fullName = os.path.join(path, f)

                            contents = "".join(open(fullName).readlines())
                            if re.search(r"[@\\]mainpage", contents):
                                self.mainpage = fullName

                if is_path_name:
                    # Path entries may need to be quoted
                    entry = quote_path(entry)

                values.append(entry)

            if name in ("DETAILS_AT_TOP",):
                continue
            elif name in ("EXAMPLE_PATTERNS",):
                continue
            elif name in ("TAGFILES", "GENERATE_TAGFILE",):
                continue
            else:
                value = sep.join(values)

            if name not in self.entries:
                self.entries[name] = ""
            else:
                self.entries[name] += sep

            self.entries[name] += value

    def __str__(self):
        val = ["# %s" % self.productName]
        #
        # Keys that appear first, and in this order.
        # The necessity for @INCLUDE_PATH to appear before @INCLUDE seems to be a feature of doxygen 1.8.2
        #
        ordered_keys = [
            "@INCLUDE_PATH",
            ]
        for k in ordered_keys:
            if k in self.entries:
                val.append("%-30s = %s" % (k, " ".join(self.entries[k].split(sep))))
                del self.entries[k]

        for k, v in self.entries.items():
            if k in ("@INCLUDE"):         # must be on separate lines.  Grrr
                for v in v.split():
                    val.append("%-30s = %s" % (k, v))
            else:
                val.append("%-30s = %s" % (k, " ".join(v.split(sep))))
        return "\n".join(val)

    def items(self):
        return self.entries.items()


def main(topProductName, products, htmlDir, useDot=True):
    configs = {}

    productList = []
    for p, v in products:
        try:
            configs[p] = Doxyfile(p, v)
            productList.append(p)

            if p == "sconsUtils":    # doesn't have a standard LSST doxygen.conf file
                configs[p].entries = dict([(k, v) for k, v in configs[p].entries.items()
                                           if k in ("EXCLUDE", "INPUT", "PROJECT_NAME",)])

        except RuntimeError as e:
            print(e, file=sys.stderr)
            if p == "lsstDoxygen":
                sys.exit(1)

    config = Doxyfile(" ".join(productList), configFile=None)  # Just init the object, no config file

    for p in productList:
        for k, v in configs[p].items():
            if k not in config.entries:
                config.entries[k] = set()

            if False:
                if isinstance(v, basestring):
                    v = [v]

            for vv in v.split(sep):
                if not vv:
                    continue

                if vv in ("yes", "no",):
                    vv = vv.upper()

                config.entries[k].add(vv)

    #
    # Fixup all but the first mainpage
    #
    def renamedMainpage(mainpage, tmpDir=tempfile.mkdtemp(prefix="lsstDoxygen")):
        if not mainpage:
            return None

        mainpage = re.sub(r"/", "_", mainpage)  # can be a Very long path

        ext = os.path.splitext(mainpage)[1]
        mainpage = hashlib.sha1(mainpage).hexdigest() + ext  # guaranteed size

        return os.path.join(tmpDir, mainpage)

    mainpage = None
    for p in productList:
        tmpName = renamedMainpage(configs[p].mainpage)
        if not tmpName:
            continue

        if not mainpage:
            mainpage = tmpName

        with open(configs[p].mainpage) as fd:
            with open(tmpName, "w") as ofd:
                for line in fd.readlines():
                    if mainpage == tmpName:
                        line = re.sub(r"\*/", "", line)  # mainpage apparently only has one comment block
                    else:
                        line = re.sub(r"[\\@]mainpage", r"\page %s" % p, line)
                    print(line, end=' ', file=ofd)

        config.entries["EXCLUDE"].add(configs[p].mainpage)
        config.entries["INPUT"].add(quote_path(tmpName))
    #
    # Add references to the ex-mainpages to the mainpage
    #
    if mainpage:
        mainpageStr = "".join(open(mainpage).readlines())

        username = re.sub("(,.*)?", "", pwd.getpwuid(os.getuid())[4])  # strip anything after a ,
        mainpageStr = mainpageStr.replace("@@USERNAME@@", username)
        mainpageStr = mainpageStr.replace("@@TOP_PRODUCT@@", topProductName)

        productList = sorted(list(set([p for p in productList if p != "lsstDoxygen"])))

        with open(mainpage, "w") as ofd:
            print(mainpageStr, file=ofd)
            if [k for k, v in configs.items() if k != "lsstDoxygen" and v.mainpage]:
                print("Packages for which documentation was gathered are:\n %s\n\n" %
                      ", ".join([re.sub(r"_", "::", "lsst::" + p) for p in productList]), file=ofd)

                print("Mainpages in sub-packages:", file=ofd)
                for i, p in enumerate(productList):
                    if False:
                        if i > 0 and p == productList[i - 1]:
                            continue

                    if p == topProductName.split()[0]:
                        continue

                    if not configs[p].mainpage:
                        continue

                    tmpName = renamedMainpage(configs[p].mainpage)

                    print(r"\li \subpage %s" % (p), file=ofd)

            print("*/", file=ofd)

    for k, v in config.items():
        if "YES" in v and "NO" in v:
            config.entries[k] = "YES"
        else:
            config.entries[k] = " ".join(config.entries[k])

    project_number = set(re.split(r"\s", config.entries.get("PROJECT_NUMBER", "")))
    config.entries["PROJECT_NUMBER"] = ",".join(sorted(project_number))
    config.entries["PROJECT_NAME"] = "LSST Applications"
    config.entries["INLINE_SOURCES"] = "YES"
    config.entries["SOURCE_BROWSER"] = "YES"
    config.entries["SEARCHENGINE"] = "YES"
    config.entries["SERVER_BASED_SEARCH"] = "YES"
    config.entries["HAVE_DOT"] = "YES" if useDot else "NO"

    config.entries["HTML_OUTPUT"] = args.htmlDir

    print(config)

if __name__ == "__main__":
    from argparse import ArgumentParser

    parser = ArgumentParser()
    parser.add_argument("--nodot", action="store_false", dest="useDot", default=True,
                        help="Don't use dot to generate diagrams")
    parser.add_argument("--htmlDir", default=os.path.join(".", "doc", "html"),
                        help="Directory to contain the generated docs")
    parser.add_argument("--setup", "-s", action="store_true", dest="asSetup", default=False,
                        help="Generate documention for as-setup versions of products")
    parser.add_argument("-i", "--ignore",
                        default="afwdata astrometry_net_data astrometry_net" +
                        " boost cfitsio doxygen eigen fftw gcc gsl lsstDoxygen minuit2" +
                        " mysqlclient numpy pyfits python scons setuptools swig wcslib xpa" +
                        " git_core toolchain gmp tcltk mpfr freetype matplotlib mpc libpng sqlite pysqlite" +
                        " suprime_data testdata_subaru meas_multifitData",
                        help="List of products that should be ignored (as they don't have doxygen.conf files)")
    parser.add_argument("product", type=str, default=True,
                        help="Product to document")
    parser.add_argument("version", type=str, default=None, nargs="?",
                        help="Version of product (current if omitted)")

    args = parser.parse_args()

    ignoredProducts += args.ignore.split()

    Eups = eups.Eups()                  # fixed in 1.2.30
    prod = Eups.findProduct(args.product, args.version)
    if not prod:
        print("Unable to find %s" % args.product, file=sys.stderr)
        sys.exit(1)

    productName = "%s %s" % (prod.name, prod.version)

    products = set()
    products.add((args.product, args.version,))
    for p in eups.getDependencies(args.product, args.version):
        name, version = p[0:2]
        if name in ignoredProducts:
            continue

        if args.asSetup:
            p = Eups.findProduct(name, eups.Tag("setup"))
            if p:
                version = p.version

        products.add((name, version))

    products = list(products)

    if "lsstDoxygen" not in products:
        products[0:0] = [("lsstDoxygen", eups.Tag("setup"))]

    main(productName, products, args.htmlDir, useDot=args.useDot)
